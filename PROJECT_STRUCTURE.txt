STRUCTURE DU PROJET MATH SCRAPER
=====================================

ğŸ“ math_scraper/
â”‚
â”œâ”€â”€ ğŸš€ START_HERE.md              â† COMMENCER ICI !
â”œâ”€â”€ ğŸ“– QUICKSTART.md              Guide rapide 5 minutes
â”œâ”€â”€ ğŸ“š README.md                  Documentation complÃ¨te
â”œâ”€â”€ ğŸ—ï¸  ARCHITECTURE.md            Explication technique dÃ©taillÃ©e
â”œâ”€â”€ ğŸ“‹ PROJECT_STRUCTURE.txt      Ce fichier
â”‚
â”œâ”€â”€ âš™ï¸ SCRIPTS PRINCIPAUX
â”‚   â”œâ”€â”€ install.sh               Installation automatique
â”‚   â”œâ”€â”€ main.py                  Orchestrateur principal (dÃ©marrer ici)
â”‚   â”œâ”€â”€ test.py                  Tests unitaires
â”‚   â”œâ”€â”€ analyze.py               Analyse du dataset collectÃ©
â”‚   â””â”€â”€ production_scraping.py   Config pour scraping production
â”‚
â”œâ”€â”€ ğŸ¤– SCRAPERS (scrapers/)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ stackexchange_scraper.py   API Stack Exchange (~500k items)
â”‚   â”œâ”€â”€ proofwiki_scraper.py       Web scraping ProofWiki (~20k)
â”‚   â”œâ”€â”€ arxiv_scraper.py           Sources LaTeX arXiv (~100k)
â”‚   â””â”€â”€ french_courses_scraper.py  Exo7, Bibmath, etc. (~50k)
â”‚
â”œâ”€â”€ ğŸ”§ UTILITAIRES (utils/)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cleaner.py               Nettoyage et validation donnÃ©es
â”‚   â””â”€â”€ storage.py               Stockage + anti-doublons
â”‚
â””â”€â”€ ğŸ“¦ CONFIGURATION
    â”œâ”€â”€ requirements.txt         DÃ©pendances Python
    â””â”€â”€ .gitignore              Fichiers Ã  ignorer (Git)


WORKFLOW D'UTILISATION
=======================

1. INSTALLATION
   ./install.sh                  (Linux/Mac)
   ou suivre instructions Windows dans START_HERE.md

2. TEST RAPIDE
   python test.py                VÃ©rifier que tout fonctionne

3. PREMIER SCRAPING
   python main.py                Collecter ~2k items (5 min)

4. ANALYSE
   python analyze.py             Voir statistiques

5. PRODUCTION
   python production_scraping.py sample      # 5k items
   python production_scraping.py production  # 600k+ items


DONNÃ‰ES GÃ‰NÃ‰RÃ‰ES
=================

math_dataset/                  (crÃ©Ã© aprÃ¨s scraping)
â”œâ”€â”€ raw/                      DonnÃ©es brutes par source
â”‚   â”œâ”€â”€ stackexchange/
â”‚   â”‚   â”œâ”€â”€ batch_YYYYMMDD_HHMMSS.json
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ proofwiki/
â”‚   â”œâ”€â”€ arxiv/
â”‚   â””â”€â”€ french_courses/
â”‚
â”œâ”€â”€ processed/                PrÃªt pour ML
â”‚   â”œâ”€â”€ train.jsonl          80% (entraÃ®nement)
â”‚   â”œâ”€â”€ validation.jsonl     10% (validation)
â”‚   â””â”€â”€ test.jsonl           10% (test)
â”‚
â”œâ”€â”€ index.json               Index anti-doublons
â””â”€â”€ scraping_stats.json      Statistiques de collecte


FORMAT DES DONNÃ‰ES
===================

Chaque item contient:
- id              : Identifiant unique
- source          : stackexchange|proofwiki|arxiv|french
- question/answer : Pour exercices
- theorem/proof   : Pour preuves formelles
- tags            : CatÃ©gories mathÃ©matiques
- language        : fr|en
- proof_structure : Type (induction, absurde, etc.)
- metadata        : Infos additionnelles

Exemple:
{
  "id": "se_12345",
  "source": "stackexchange",
  "question": "Montrer que pour tout n âˆˆ â„•...",
  "answer": "Par rÃ©currence...",
  "proof_structure": {
    "type": "induction",
    "techniques": ["mathematical_induction"],
    "steps": ["base_case", "inductive_step"]
  },
  "tags": ["induction", "number-theory"],
  "language": "fr",
  "score": 42
}


VOLUMÃ‰TRIE ATTENDUE
====================

Source              Items      Temps    QualitÃ©
----------------------------------------------
Stack Exchange      500,000    2-3h     â­â­â­â­
ProofWiki           20,000     1h       â­â­â­â­â­
arXiv               100,000    10-15h   â­â­â­â­
Cours franÃ§ais      50,000     2-3h     â­â­â­â­
----------------------------------------------
TOTAL               670,000+   16-24h


CARACTÃ‰RISTIQUES DU SYSTÃˆME
=============================

âœ… Production-ready
   - Gestion erreurs robuste
   - Rate limiting respectÃ©
   - Sauvegarde incrÃ©mentale
   - Peut Ãªtre interrompu/repris

âœ… Scalable
   - Scrapers parallÃ¨les (asyncio)
   - Anti-doublons automatique
   - Pas de limite de taille

âœ… QualitÃ©
   - Filtres validation multiples
   - DÃ©tection langue (FR/EN)
   - Extraction structure preuve
   - Nettoyage HTML/LaTeX

âœ… Flexible
   - Facile d'ajouter sources
   - Configuration personnalisable
   - Multiples formats export


PROCHAINES Ã‰TAPES APRÃˆS SCRAPING
==================================

1. Exploration des donnÃ©es
   python analyze.py

2. PrÃ©paration pour Lean
   - Parser structure mathÃ©matique
   - CrÃ©er templates conversion
   - Normaliser notations

3. Fine-tuning modÃ¨le (avec 4Ã—A100)
   - Fine-tune DeepSeek-Prover (7B)
   - Ou LLEMMA
   - LoRA/QLoRA pour optimiser mÃ©moire
   - Dataset: math_dataset/processed/train.jsonl

4. Validation
   - Utiliser compilateur Lean
   - VÃ©rifier outputs gÃ©nÃ©rÃ©s
   - ItÃ©rer sur qualitÃ©


LIENS UTILES
=============

Stack Exchange API:
  https://api.stackexchange.com/docs

ProofWiki:
  https://proofwiki.org

arXiv bulk data:
  https://arxiv.org/help/bulk_data

Lean documentation:
  https://leanprover.github.io

DeepSeek-Prover:
  https://github.com/deepseek-ai/DeepSeek-Prover


SUPPORT & DÃ‰PANNAGE
====================

Logs dÃ©taillÃ©s: scraping.log

ProblÃ¨mes courants:
- Rate limit exceeded â†’ Attendre ou clÃ© API
- Scraping lent â†’ Normal pour arXiv
- Espace disque â†’ ~3 GB pour production

Tous les tests passent? â†’ PrÃªt Ã  l'emploi! ğŸ‰
